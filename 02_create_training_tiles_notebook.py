# %% [markdown]
# # π“¦ Training Tiles Generation (Sliding Window)
#
# λ€ν• μƒν” (2048Γ—2048)μ—μ„ 256Γ—256 νƒ€μΌμ„ μ¶”μ¶ν•©λ‹λ‹¤.
#
# ## π“‹ λ©μ°¨
# 1. ν™κ²½ μ„¤μ • λ° μ„ν¬νΈ
# 2. νλΌλ―Έν„° μ„¤μ •
# 3. νƒ€μΌ μƒμ„±
# 4. μƒμ„±λ νƒ€μΌ ν™•μΈ λ° μ‹κ°ν™”

# %% [markdown]
# ## 1. ν™κ²½ μ„¤μ • λ° μ„ν¬νΈ

# %%
import numpy as np
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
import json
import random
from tqdm import tqdm

# μ‹κ°ν™” μ„¤μ •
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 10

print("β… λ¨λ“  λΌμ΄λΈλ¬λ¦¬ μ„ν¬νΈ μ™„λ£!")

# %% [markdown]
# ## 2. νλΌλ―Έν„° μ„¤μ •

# %%
# ==================== νƒ€μΌ μƒμ„± νλΌλ―Έν„° ====================
DATA_DIR = 'data/forward_intensity'          # λ€ν• μƒν” λ””λ ‰ν† λ¦¬
OUTPUT_DIR = 'data/forward_intensity_tiles'  # νƒ€μΌ μ¶λ ¥ λ””λ ‰ν† λ¦¬
TILE_SIZE = 256                          # νƒ€μΌ ν¬κΈ°
NUM_TILES_PER_SAMPLE = 1000              # μƒν”λ‹Ή νƒ€μΌ κ°μ
TRAIN_SAMPLES = 8                        # ν›λ ¨μ© μƒν” κ°μ
VAL_SAMPLES = 2                          # κ²€μ¦μ© μƒν” κ°μ
RANDOM_SEED = 42                         # λλ¤ μ‹λ“

# λλ¤ μ‹λ“ μ„¤μ •
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

print("β… νλΌλ―Έν„° μ„¤μ • μ™„λ£!")
print(f"\nπ“ νƒ€μΌ μƒμ„± μ •λ³΄:")
print(f"   μ†μ¤ λ””λ ‰ν† λ¦¬: {DATA_DIR}")
print(f"   μ¶λ ¥ λ””λ ‰ν† λ¦¬: {OUTPUT_DIR}")
print(f"   νƒ€μΌ ν¬κΈ°: {TILE_SIZE}Γ—{TILE_SIZE}")
print(f"   μƒν”λ‹Ή νƒ€μΌ κ°μ: {NUM_TILES_PER_SAMPLE}")
print(f"   ν›λ ¨ μƒν”: {TRAIN_SAMPLES} β†’ {TRAIN_SAMPLES * NUM_TILES_PER_SAMPLE:,} νƒ€μΌ")
print(f"   κ²€μ¦ μƒν”: {VAL_SAMPLES} β†’ {VAL_SAMPLES * NUM_TILES_PER_SAMPLE:,} νƒ€μΌ")
print(f"   μ΄ νƒ€μΌ: {(TRAIN_SAMPLES + VAL_SAMPLES) * NUM_TILES_PER_SAMPLE:,}")

# %% [markdown]
# ## 3. νƒ€μΌ μ¶”μ¶ ν•¨μ μ •μ

# %%
def extract_random_tile(image, tile_size):
    """Extract a random tile from the image"""
    h, w = image.shape
    
    if h < tile_size or w < tile_size:
        raise ValueError(f"Image size {image.shape} is too small for tile size {tile_size}")
    
    max_y = h - tile_size
    max_x = w - tile_size
    
    top_y = random.randint(0, max_y)
    top_x = random.randint(0, max_x)
    
    tile = image[top_y:top_y+tile_size, top_x:top_x+tile_size]
    
    return tile, (top_y, top_x)

print("β… νƒ€μΌ μ¶”μ¶ ν•¨μ μ •μ μ™„λ£!")

# %% [markdown]
# ## 4. λ°μ΄ν„° ν™•μΈ

# %%
data_dir = Path(DATA_DIR)
input_dir = data_dir / 'inputs'
output_dir_src = data_dir / 'outputs'

# μ‚¬μ© κ°€λ¥ν• μƒν” ν™•μΈ
all_samples = sorted(list(input_dir.glob('*.png')))

print(f"π“‚ μ‚¬μ© κ°€λ¥ν• μƒν”: {len(all_samples)}κ°")

if len(all_samples) < TRAIN_SAMPLES + VAL_SAMPLES:
    print(f"\nβ οΈ  κ²½κ³ : ν•„μ”ν• μƒν” μ({TRAIN_SAMPLES + VAL_SAMPLES})λ³΄λ‹¤ μ μµλ‹λ‹¤!")
    print(f"   μ‚¬μ© κ°€λ¥: {len(all_samples)}κ°")
else:
    print(f"   β†’ μ¶©λ¶„ν• μƒν”μ΄ μμµλ‹λ‹¤!")

# %% [markdown]
# ## 5. νƒ€μΌ μƒμ„± - ν›λ ¨ μ„ΈνΈ

# %%
# μ¶λ ¥ λ””λ ‰ν† λ¦¬ μƒμ„±
output_path = Path(OUTPUT_DIR)
for split in ['train', 'val']:
    (output_path / split / 'inputs').mkdir(parents=True, exist_ok=True)
    (output_path / split / 'outputs').mkdir(parents=True, exist_ok=True)

# μƒν” λ¶„ν• 
random.shuffle(all_samples)
train_sample_files = all_samples[:TRAIN_SAMPLES]
val_sample_files = all_samples[TRAIN_SAMPLES:TRAIN_SAMPLES+VAL_SAMPLES]

print("="*80)
print("π”¨ ν›λ ¨ νƒ€μΌ μƒμ„± μ¤‘...")
print("="*80)

tile_idx = 0
for sample_file in tqdm(train_sample_files, desc="Training samples"):
    # μ…λ ¥/μ¶λ ¥ λ΅λ“
    input_path = data_dir / 'inputs' / sample_file.name
    output_npy_path = data_dir / 'outputs' / (sample_file.stem + '.npy')
    
    input_img = cv2.imread(str(input_path), cv2.IMREAD_GRAYSCALE)
    output_intensity = np.load(output_npy_path)
    
    if input_img is None:
        print(f"  β οΈ  Failed to load {input_path}")
        continue
    
    # ν¬κΈ°κ°€ λ‹¤λ¥΄λ©΄ μ΅°μ •
    if input_img.shape != output_intensity.shape:
        input_img = cv2.resize(input_img, (output_intensity.shape[1], output_intensity.shape[0]), 
                              interpolation=cv2.INTER_NEAREST)
    
    # νƒ€μΌ μ¶”μ¶
    for _ in range(NUM_TILES_PER_SAMPLE):
        try:
            # μ…λ ¥ νƒ€μΌ
            input_tile, (top_y, top_x) = extract_random_tile(input_img, TILE_SIZE)
            
            # μ¶λ ¥ νƒ€μΌ
            output_tile = output_intensity[top_y:top_y+TILE_SIZE, top_x:top_x+TILE_SIZE]
            
            # μ €μ¥
            tile_name = f"tile_{tile_idx:06d}"
            cv2.imwrite(str(output_path / 'train' / 'inputs' / f"{tile_name}.png"), input_tile)
            np.save(str(output_path / 'train' / 'outputs' / f"{tile_name}.npy"), output_tile)
            
            tile_idx += 1
            
        except Exception as e:
            print(f"  β οΈ  Failed to extract tile: {e}")
            continue

print(f"\nβ… ν›λ ¨ νƒ€μΌ {tile_idx}κ° μƒμ„± μ™„λ£!")

# %% [markdown]
# ## 6. νƒ€μΌ μƒμ„± - κ²€μ¦ μ„ΈνΈ

# %%
print("\n" + "="*80)
print("π”¨ κ²€μ¦ νƒ€μΌ μƒμ„± μ¤‘...")
print("="*80)

tile_idx = 0
for sample_file in tqdm(val_sample_files, desc="Validation samples"):
    # μ…λ ¥/μ¶λ ¥ λ΅λ“
    input_path = data_dir / 'inputs' / sample_file.name
    output_npy_path = data_dir / 'outputs' / (sample_file.stem + '.npy')
    
    input_img = cv2.imread(str(input_path), cv2.IMREAD_GRAYSCALE)
    output_intensity = np.load(output_npy_path)
    
    if input_img is None:
        print(f"  β οΈ  Failed to load {input_path}")
        continue
    
    # ν¬κΈ°κ°€ λ‹¤λ¥΄λ©΄ μ΅°μ •
    if input_img.shape != output_intensity.shape:
        input_img = cv2.resize(input_img, (output_intensity.shape[1], output_intensity.shape[0]), 
                              interpolation=cv2.INTER_NEAREST)
    
    # νƒ€μΌ μ¶”μ¶
    for _ in range(NUM_TILES_PER_SAMPLE):
        try:
            # μ…λ ¥ νƒ€μΌ
            input_tile, (top_y, top_x) = extract_random_tile(input_img, TILE_SIZE)
            
            # μ¶λ ¥ νƒ€μΌ
            output_tile = output_intensity[top_y:top_y+TILE_SIZE, top_x:top_x+TILE_SIZE]
            
            # μ €μ¥
            tile_name = f"tile_{tile_idx:06d}"
            cv2.imwrite(str(output_path / 'val' / 'inputs' / f"{tile_name}.png"), input_tile)
            np.save(str(output_path / 'val' / 'outputs' / f"{tile_name}.npy"), output_tile)
            
            tile_idx += 1
            
        except Exception as e:
            print(f"  β οΈ  Failed to extract tile: {e}")
            continue

print(f"\nβ… κ²€μ¦ νƒ€μΌ {tile_idx}κ° μƒμ„± μ™„λ£!")

# %% [markdown]
# ## 7. λ©”νƒ€λ°μ΄ν„° μ €μ¥

# %%
metadata = {
    'tile_size': TILE_SIZE,
    'num_tiles_per_sample': NUM_TILES_PER_SAMPLE,
    'train_samples': TRAIN_SAMPLES,
    'val_samples': VAL_SAMPLES,
    'train_total_tiles': TRAIN_SAMPLES * NUM_TILES_PER_SAMPLE,
    'val_total_tiles': VAL_SAMPLES * NUM_TILES_PER_SAMPLE,
    'train_sample_files': [str(f.name) for f in train_sample_files],
    'val_sample_files': [str(f.name) for f in val_sample_files],
    'random_seed': RANDOM_SEED
}

metadata_path = output_path / 'tiles_metadata.json'
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)

print("β… λ©”νƒ€λ°μ΄ν„° μ €μ¥ μ™„λ£!")

# %% [markdown]
# ## 8. μƒμ„±λ νƒ€μΌ ν™•μΈ

# %%
# νμΌ κ°μ ν™•μΈ
train_input_tiles = list((output_path / 'train' / 'inputs').glob('*.png'))
train_output_tiles = list((output_path / 'train' / 'outputs').glob('*.npy'))
val_input_tiles = list((output_path / 'val' / 'inputs').glob('*.png'))
val_output_tiles = list((output_path / 'val' / 'outputs').glob('*.npy'))

print("\n" + "="*80)
print("π‰ νƒ€μΌ μƒμ„± μ™„λ£!")
print("="*80)
print(f"\nπ“ μƒμ„±λ νƒ€μΌ:")
print(f"   ν›λ ¨ μ„ΈνΈ:")
print(f"     β€Ά μ…λ ¥: {len(train_input_tiles):,}κ°")
print(f"     β€Ά μ¶λ ¥: {len(train_output_tiles):,}κ°")
print(f"   κ²€μ¦ μ„ΈνΈ:")
print(f"     β€Ά μ…λ ¥: {len(val_input_tiles):,}κ°")
print(f"     β€Ά μ¶λ ¥: {len(val_output_tiles):,}κ°")
print(f"   μ΄ νƒ€μΌ: {len(train_input_tiles) + len(val_input_tiles):,}κ°")

# %% [markdown]
# ## 9. νƒ€μΌ μ‹κ°ν™”

# %%
# λλ¤ν•κ² 6κ° νƒ€μΌ μ‹κ°ν™”
num_to_show = 6
sample_indices = random.sample(range(len(train_input_tiles)), num_to_show)

fig, axes = plt.subplots(num_to_show, 3, figsize=(12, 4*num_to_show))

for idx, tile_idx in enumerate(sample_indices):
    # νƒ€μΌ λ΅λ“
    input_tile_path = train_input_tiles[tile_idx]
    output_tile_path = output_path / 'train' / 'outputs' / (input_tile_path.stem + '.npy')
    
    input_tile = cv2.imread(str(input_tile_path), cv2.IMREAD_GRAYSCALE)
    intensity_tile = np.load(output_tile_path)
    
    # μ…λ ¥ νƒ€μΌ
    axes[idx, 0].imshow(input_tile, cmap='gray')
    axes[idx, 0].set_title(f'Tile {tile_idx}: Input\n{input_tile.shape}')
    axes[idx, 0].axis('off')
    
    # Intensity νƒ€μΌ
    im = axes[idx, 1].imshow(intensity_tile, cmap='hot')
    axes[idx, 1].set_title(f'Tile {tile_idx}: EM Intensity\n{intensity_tile.shape}')
    axes[idx, 1].axis('off')
    plt.colorbar(im, ax=axes[idx, 1], fraction=0.046)
    
    # νμ¤ν† κ·Έλ¨
    axes[idx, 2].hist(intensity_tile.flatten(), bins=30, alpha=0.7, color='red', edgecolor='black')
    axes[idx, 2].set_xlabel('Intensity')
    axes[idx, 2].set_ylabel('Count')
    axes[idx, 2].set_title(f'Tile {tile_idx}: Distribution')
    axes[idx, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nβ… {num_to_show}κ° νƒ€μΌ μ‹κ°ν™” μ™„λ£!")

# %% [markdown]
# ## 10. λ‹¤μ λ‹¨κ³„
#
# νƒ€μΌ μƒμ„±μ΄ μ™„λ£λμ—μµλ‹λ‹¤! λ‹¤μ λ…ΈνΈλ¶μΌλ΅ μ΄λ™ν•μ„Έμ”:
#
# **`03_train_model_notebook.py`**: U-Net λ¨λΈ ν•™μµ

# %%

